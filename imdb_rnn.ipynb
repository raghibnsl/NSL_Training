{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-14 14:51:01.728097: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-14 14:51:01.958863: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-12-14 14:51:02.016643: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-14 14:51:02.016659: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-14 14:51:02.053408: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-14 14:51:02.917871: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-14 14:51:02.917940: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-14 14:51:02.917946: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "da5b8a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    DATASET_PATH=\"imdb_dataset\"\n",
    "\n",
    "    BATCH_SIZE=1024\n",
    "    BUFFER_SIZE=BATCH_SIZE*2\n",
    "\n",
    "    VOCAB_SIZE=20000\n",
    "    MAX_SEQ_LEN=50\n",
    "\n",
    "    EPOCHS=15\n",
    "\n",
    "    LR=1e-4\n",
    "    autotune=tf.data.AUTOTUNE\n",
    "    OUTPUT_PATH='output'\n",
    "    RNN_MODEL_PATH=os.path.join(OUTPUT_PATH,'rnn_model')\n",
    "    LSTM_MODEL_PATH=os.path.join(OUTPUT_PATH,'lstm_model')\n",
    "    TEXT_VEC_PATH=os.path.join(OUTPUT_PATH,'text_vec')\n",
    "\n",
    "    RNN_PLOT=os.path.join(OUTPUT_PATH,'rnn_plot.png')\n",
    "    LSTM_PLOT=os.path.join(OUTPUT_PATH,'lstm_plot.png')\n",
    "    URL = 'https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
    "    FILE_NAME='aclImdb'\n",
    "    DATASET_NAME='aclImdb_v1.tar.gz'\n",
    "    EMBEDDING_SIZE=100  \n",
    "config=config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "05dc5078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 20000 files for training.\n",
      "Found 25000 files belonging to 2 classes.\n",
      "Using 5000 files for validation.\n",
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "def fetch_dataset(url,dataName,fileName):\n",
    "    dataset=tf.keras.utils.get_file('aclImdb_v1.tar.gz',url,untar=True,cache_dir='.',cache_subdir='')\n",
    "    dataset_dir=os.path.join(os.path.dirname(dataset),fileName)\n",
    "    train_dir=os.path.join(dataset_dir,'train')\n",
    "    shutil.rmtree(os.path.join(train_dir,'unsup'))\n",
    "    rawTrainDS=tf.keras.utils.text_dataset_from_directory(train_dir,batch_size=config.BATCH_SIZE,validation_split=0.2,subset='training',seed=42)\n",
    "    rawValDS=tf.keras.utils.text_dataset_from_directory(train_dir,batch_size=config.BATCH_SIZE,validation_split=0.2,subset='validation',seed=42)\n",
    "    rawTestDS=tf.keras.utils.text_dataset_from_directory(config.FILE_NAME+'/test',batch_size=config.BATCH_SIZE)\n",
    "    \n",
    "    rawTrainDS=rawTrainDS.cache().prefetch(config.autotune)\n",
    "    rawValDS=rawValDS.cache().prefetch(config.autotune)\n",
    "    rawTestDS=rawTestDS.cache().prefetch(config.autotune)\n",
    "    return (rawTrainDS,rawValDS,rawTestDS)\n",
    "with tf.device('/cpu:0'):\n",
    "    rawTrainDS,rawValDS,rawTestDS=fetch_dataset(url=config.URL,dataName=config.DATASET_NAME,fileName=config.FILE_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d77f7f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([b\"I married a Japanese woman 14 years ago. We're still together.<br /><br />However in the 1950's it would never have been as easy.<br /><br />Life in the military had been mined for action, drama, and comedy for years by this point. Mined to death. The mixed relationships gave it new ground to cover. This is old hat today, but then...? Marrying an Asian back then meant you either owed somebody something or you were a freak of some sort. This touched on both possibilities along with the third. Maybe it IS love? <br /><br />Brando did his usual good job. Garner did a better job than he usually does. He's good, but this showed how good he could be. Umecki-chan had a helluva debut here and while I think she earned her statue, she didn't really stretch. It was a role that no one who hadn't been overseas would have recognized and the newness was the corker.<br /><br />The real scene stealer was Red Buttons. Red was the best thing in this film. Bank on it. And the Japanese lifestyles were shown in an admirable light as well.<br /><br />A classic.\"], shape=(1,), dtype=string)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-15 16:04:32.354145: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for i,j in rawTrainDS.take(1):\n",
    "    print(i[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "73432d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder=tf.keras.layers.TextVectorization(max_tokens=config.VOCAB_SIZE)\n",
    "encoder.adapt(rawTrainDS.map(lambda text,label:text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d41a7bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in rawTrainDS.take(1):\n",
    "    example=i[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "c6f0cc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class build_RNN(tf.keras.Model):\n",
    "    def __init__(self,rnn_cells,vocab_size,emb_dim):\n",
    "        super().__init__(self)\n",
    "        self.emb=tf.keras.layers.Embedding(vocab_size,emb_dim)\n",
    "        self.lstm=tf.keras.layers.LSTM(rnn_cells,return_sequences=False,return_state=True)\n",
    "        self.fc_1=tf.keras.layers.Dense(1000,kernel_initializer=tf.initializers.glorot_normal())\n",
    "        self.fc_out=tf.keras.layers.Dense(1,activation='sigmoid') \n",
    "    def call(self,inputs,states=None,training=False,return_state=False):\n",
    "        emb=self.emb(inputs,training=training)\n",
    "        if not states:\n",
    "            states=self.lstm.get_initial_state(emb)\n",
    "        x,*states=self.lstm(emb,initial_state=states,training=training)\n",
    "        x=self.fc_1(x,training=training)\n",
    "        x=self.fc_out(x,training=training)\n",
    "        if return_state:\n",
    "            return (x,states)\n",
    "        else:\n",
    "            return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "57e8e57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=build_RNN(rnn_cells=500,vocab_size=config.VOCAB_SIZE,emb_dim=config.EMBEDDING_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "024e0966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
       "array([[0.50031555],\n",
       "       [0.50031555],\n",
       "       [0.50031555],\n",
       "       [0.50031555],\n",
       "       [0.50031555],\n",
       "       [0.50031555],\n",
       "       [0.50031555],\n",
       "       [0.5012726 ],\n",
       "       [0.50031555],\n",
       "       [0.50031555]], dtype=float32)>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "bb39d3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"build_rnn_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_11 (Embedding)    multiple                  2000000   \n",
      "                                                                 \n",
      " lstm_12 (LSTM)              multiple                  1202000   \n",
      "                                                                 \n",
      " dense_24 (Dense)            multiple                  501000    \n",
      "                                                                 \n",
      " dense_25 (Dense)            multiple                  1001      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,704,001\n",
      "Trainable params: 3,704,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d10c74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('eda_')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "4fd5fc177e0ac63e843aff7592077441a1851d922926b32a453148371f9de21f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
